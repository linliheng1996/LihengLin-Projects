EE451 Fall 2019 Final Project
Parallelization of Kempeâ€™s Influence Maximization Algorithm
Yi Sui, Liheng Lin, Pengcheng Li

The source files are intended to be run on USC HPC:

1. Log onto user@hpc-login3.usc.edu
2. run "source /usr/usc/openmpi/default/setup.sh"
3. run "make" to compile and generate the executables

Serial Implementation:
    -Run "sbatch serial.sl" to submit the job to be run on HPC using slurm
    
    -(Optional)run "squeue --user=$USER" to check progress
    
    -The default seed size and sample times to run are both 10
    
    -The output would be stored in serial-output.txt
    
    -serial.sl can be modified to run the test with different parameters, or with diffrent resources allocation time
    
    For example:
    srun --ntasks=${SLURM_NTASKS} ./serial 1 2 > serial-output.txt
    // this would run it with seed size = 1 and sample times = 2
    
    
MPI Static Mapping Implementation:
    -Run "sbatch mpi-static.sl" to submit the job to be run on HPC using slurm
    
    -(Optional)run "squeue --user=$USER" to check progress
    
    -The default seed size and sample times to run are both 10
    
    -The output would be stored in mpi-static-output.txt
    
    - mpi-static.sl can be modified to run the test with different parameters, or with diffrent resources allocation time, or with different number of computing nodes(workers)
    
    For example:
    srun --ntasks=${SLURM_NTASKS} --mpi=pmi2 ./mpi-static 1 2 > mpi-static-output.txt  
    // this would run it with seed size = 1 and sample times = 2
    
    
MPI Dynamic Mapping Implementation:
    -Run "sbatch mpi-dynamic.sl" to submit the job to be run on HPC using slurm
    
    -(Optional)run "squeue --user=$USER" to check progress
    
    -The default seed size and sample times to run are both 10
    
    -The default block size is 10
    
    -The output would be stored in mpi-dynamic-output.txt
    
    -mpi-dynamic.sl can be modified to run the test with different parameters, or with diffrent resources allocation time, or with different number of computing nodes(workers)
    
    For example:
    srun --ntasks=${SLURM_NTASKS} --mpi=pmi2 ./mpi-dynamic 1 2 50 > mpi-dynamic-output.txt  
    // this would run it with seed size = 1, sample times = 2, and block size = 50
    
    
MPI Graph Partition Implementation:
    -Run "sbatch graph-partition.sl" to submit the job to be run on HPC using slurm
    
    -(Optional)run "squeue --user=$USER" to check progress
    
    -The default seed size and sample times to run are both 1
    
    -The output would be stored in graph-partition-output.txt
    
    -graph-partition.scan be modified to run the test with different parameters, or with diffrent resources allocation time, or with different number of computing nodes(workers)
    
    For example:
    srun --ntasks=${SLURM_NTASKS} --mpi=pmi2 ./graph-partition 1 2 > graph-partition-output.txt 
    // this would run it with seed size = 1, sample times = 2
    
    
Testing dataset is store in dataset/
    - soc-sign-bitcoinotc.csv and soc-sign-bitcoinotc.csv.gz are the raw data set files obtained from the Stanford Large Network Dataset Collection website.
    
    - dataset.csv are the processed dataset, generated by data.py, to be used in our project
    
    - tastset1.csv and testset2.csv are two small network graph dataset that we made for testing and debugging. To use these two dataset, the source files needed to be modified: inside of readfile.cpp, change the input file path.
